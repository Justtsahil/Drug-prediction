{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFdEUhJ9Yc1T",
        "outputId": "a3e5c066-0fdc-4a71-fdc7-589015cdb635"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported.\n",
            "--- Training Model on SYNTHETIC Dataset (v2) ---\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Setup & Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import joblib # For saving models/preprocessors\n",
        "import json # For pretty printing dicts\n",
        "from collections import defaultdict # For mappings\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Model\n",
        "import lightgbm as lgb\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Suppress specific warnings if needed\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "print(\"Libraries imported.\")\n",
        "print(\"--- Training Model on SYNTHETIC Dataset (v2) ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9XAfPmpYvCn",
        "outputId": "a72366d7-a855-4733-cae9-e4110e81ec2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to load data from: /content/Synthetic_Medical_Dataset_v2.csv\n",
            "\n",
            "Data loaded successfully from /content/Synthetic_Medical_Dataset_v2.csv\n",
            "Dataset shape: (15000, 36)\n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15000 entries, 0 to 14999\n",
            "Data columns (total 36 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   Patient_ID                   15000 non-null  int64  \n",
            " 1   Age                          15000 non-null  int64  \n",
            " 2   Gender                       15000 non-null  object \n",
            " 3   Blood_Group                  15000 non-null  object \n",
            " 4   Weight_kg                    15000 non-null  float64\n",
            " 5   Has_Fever                    15000 non-null  int64  \n",
            " 6   Has_Cough                    15000 non-null  int64  \n",
            " 7   Has_Fatigue                  15000 non-null  int64  \n",
            " 8   Has_Pain                     15000 non-null  int64  \n",
            " 9   Has_Hypertension             15000 non-null  int64  \n",
            " 10  Has_Diabetes                 15000 non-null  int64  \n",
            " 11  Temperature_C                15000 non-null  float64\n",
            " 12  Heart_Rate                   15000 non-null  int64  \n",
            " 13  BP_Systolic                  15000 non-null  int64  \n",
            " 14  WBC_Count                    15000 non-null  float64\n",
            " 15  Glucose_Level                15000 non-null  int64  \n",
            " 16  Predicted_Disease            15000 non-null  object \n",
            " 17  Disease_Causes               15000 non-null  object \n",
            " 18  Medicine_1                   13916 non-null  object \n",
            " 19  Dosage_1                     13916 non-null  object \n",
            " 20  Frequency_1                  13916 non-null  object \n",
            " 21  Duration_1                   13916 non-null  object \n",
            " 22  Instructions_1               13916 non-null  object \n",
            " 23  Medicine_2                   12773 non-null  object \n",
            " 24  Dosage_2                     12773 non-null  object \n",
            " 25  Frequency_2                  12773 non-null  object \n",
            " 26  Duration_2                   12773 non-null  object \n",
            " 27  Instructions_2               12773 non-null  object \n",
            " 28  Medicine_3                   3512 non-null   object \n",
            " 29  Dosage_3                     3512 non-null   object \n",
            " 30  Frequency_3                  3512 non-null   object \n",
            " 31  Duration_3                   3512 non-null   object \n",
            " 32  Instructions_3               3512 non-null   object \n",
            " 33  Personalized_Health_Tips     15000 non-null  object \n",
            " 34  Polypharmacy_Risk            15000 non-null  object \n",
            " 35  Polypharmacy_Recommendation  15000 non-null  object \n",
            "dtypes: float64(3), int64(11), object(22)\n",
            "memory usage: 4.1+ MB\n",
            "\n",
            "Sample Records (showing potential inputs and outputs):\n",
            "   Patient_ID  Age Gender Blood_Group  Weight_kg  Has_Fever  Has_Cough  \\\n",
            "0           1   61   Male          B+       92.9          0          0   \n",
            "1           2   45   Male         AB+       82.7          0          0   \n",
            "2           3   23   Male          B+       64.0          0          0   \n",
            "\n",
            "   Has_Fatigue  Has_Pain  Has_Hypertension  ...       Duration_2  \\\n",
            "0            0         1                 0  ...        As needed   \n",
            "1            1         0                 1  ...  Short-term only   \n",
            "2            1         1                 0  ...        As needed   \n",
            "\n",
            "                                      Instructions_2  Medicine_3  Dosage_3  \\\n",
            "0                           Apply to affected joint.         NaN       NaN   \n",
            "1  For panic attacks, use sparingly due to depend...         NaN       NaN   \n",
            "2                           Apply to affected joint.         NaN       NaN   \n",
            "\n",
            "   Frequency_3  Duration_3 Instructions_3  \\\n",
            "0          NaN         NaN            NaN   \n",
            "1          NaN         NaN            NaN   \n",
            "2          NaN         NaN            NaN   \n",
            "\n",
            "                            Personalized_Health_Tips Polypharmacy_Risk  \\\n",
            "0  Maintain healthy weight, low-impact exercise (...               Low   \n",
            "1  Cognitive behavioral therapy (CBT), stress man...            Medium   \n",
            "2  Maintain healthy weight, low-impact exercise (...               Low   \n",
            "\n",
            "                         Polypharmacy_Recommendation  \n",
            "0  Monitor liver function with high-dose acetamin...  \n",
            "1  Monitor for side effects of SSRI. Caution with...  \n",
            "2  Monitor liver function with high-dose acetamin...  \n",
            "\n",
            "[3 rows x 36 columns]\n",
            "\n",
            "Checking for missing values (should be few or none from generation):\n",
            "Patient_ID                         0\n",
            "Age                                0\n",
            "Gender                             0\n",
            "Blood_Group                        0\n",
            "Weight_kg                          0\n",
            "Has_Fever                          0\n",
            "Has_Cough                          0\n",
            "Has_Fatigue                        0\n",
            "Has_Pain                           0\n",
            "Has_Hypertension                   0\n",
            "Has_Diabetes                       0\n",
            "Temperature_C                      0\n",
            "Heart_Rate                         0\n",
            "BP_Systolic                        0\n",
            "WBC_Count                          0\n",
            "Glucose_Level                      0\n",
            "Predicted_Disease                  0\n",
            "Disease_Causes                     0\n",
            "Medicine_1                      1084\n",
            "Dosage_1                        1084\n",
            "Frequency_1                     1084\n",
            "Duration_1                      1084\n",
            "Instructions_1                  1084\n",
            "Medicine_2                      2227\n",
            "Dosage_2                        2227\n",
            "Frequency_2                     2227\n",
            "Duration_2                      2227\n",
            "Instructions_2                  2227\n",
            "Medicine_3                     11488\n",
            "Dosage_3                       11488\n",
            "Frequency_3                    11488\n",
            "Duration_3                     11488\n",
            "Instructions_3                 11488\n",
            "Personalized_Health_Tips           0\n",
            "Polypharmacy_Risk                  0\n",
            "Polypharmacy_Recommendation        0\n",
            "dtype: int64\n",
            "\n",
            "Missing values handled (if any).\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Load Data\n",
        "# --- Use the SYNTHETIC dataset generated previously ---\n",
        "file_path = '/content/Synthetic_Medical_Dataset_v2.csv'\n",
        "\n",
        "print(f\"Attempting to load data from: {file_path}\")\n",
        "try:\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(f\"\\nData loaded successfully from {file_path}\")\n",
        "    print(f\"Dataset shape: {df.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {file_path}\")\n",
        "    print(\"Please ensure the 'Synthetic_Medical_Dataset_v2.csv' file is in the correct directory.\")\n",
        "    raise SystemExit(\"Stopping execution: Dataset not found.\")\n",
        "\n",
        "# Display basic info\n",
        "print(\"\\nDataset Info:\")\n",
        "df.info()\n",
        "print(\"\\nSample Records (showing potential inputs and outputs):\")\n",
        "print(df.head(3))\n",
        "print(\"\\nChecking for missing values (should be few or none from generation):\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Simple Fillna just in case (using mode for categorical, 0 for numerical)\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        df[col] = df[col].fillna(df[col].mode()[0])\n",
        "    elif pd.api.types.is_numeric_dtype(df[col]) and col != 'Patient_ID':\n",
        "         # Fill numerical NaNs (except Patient_ID) with 0 - adjust if median/mean is better\n",
        "         df[col] = df[col].fillna(0)\n",
        "\n",
        "print(\"\\nMissing values handled (if any).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcNyXHN_Y5-3",
        "outputId": "b8eae33f-a9a1-4320-b031-e0edafbdaf64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Data Preparation & Exploratory Analysis ---\n",
            "Loaded main dataset with 15000 rows and 36 columns\n",
            "Note: No separate mappings file loaded: [Errno 2] No such file or directory: 'disease_mappings.csv'\n",
            "\n",
            "Data Overview:\n",
            "   Patient_ID  Age  Gender Blood_Group  Weight_kg  Has_Fever  Has_Cough  \\\n",
            "0           1   61    Male          B+       92.9          0          0   \n",
            "1           2   45    Male         AB+       82.7          0          0   \n",
            "2           3   23    Male          B+       64.0          0          0   \n",
            "3           4   49  Female          B-       77.1          1          0   \n",
            "4           5   44  Female          O+       99.3          0          0   \n",
            "\n",
            "   Has_Fatigue  Has_Pain  Has_Hypertension  ...       Duration_2  \\\n",
            "0            0         1                 0  ...        As needed   \n",
            "1            1         0                 1  ...  Short-term only   \n",
            "2            1         1                 0  ...        As needed   \n",
            "3            0         1                 0  ...        As needed   \n",
            "4            1         0                 0  ...  Short-term only   \n",
            "\n",
            "                                      Instructions_2  Medicine_3  Dosage_3  \\\n",
            "0                           Apply to affected joint.         NaN       NaN   \n",
            "1  For panic attacks, use sparingly due to depend...         NaN       NaN   \n",
            "2                           Apply to affected joint.         NaN       NaN   \n",
            "3                             For fever/pain relief.         NaN       NaN   \n",
            "4  For panic attacks, use sparingly due to depend...         NaN       NaN   \n",
            "\n",
            "   Frequency_3  Duration_3 Instructions_3  \\\n",
            "0          NaN         NaN            NaN   \n",
            "1          NaN         NaN            NaN   \n",
            "2          NaN         NaN            NaN   \n",
            "3          NaN         NaN            NaN   \n",
            "4          NaN         NaN            NaN   \n",
            "\n",
            "                            Personalized_Health_Tips Polypharmacy_Risk  \\\n",
            "0  Maintain healthy weight, low-impact exercise (...               Low   \n",
            "1  Cognitive behavioral therapy (CBT), stress man...            Medium   \n",
            "2  Maintain healthy weight, low-impact exercise (...               Low   \n",
            "3  Get annual flu shot, rest, fluids, avoid contact.            Medium   \n",
            "4  Cognitive behavioral therapy (CBT), stress man...            Medium   \n",
            "\n",
            "                         Polypharmacy_Recommendation  \n",
            "0  Monitor liver function with high-dose acetamin...  \n",
            "1  Monitor for side effects of SSRI. Caution with...  \n",
            "2  Monitor liver function with high-dose acetamin...  \n",
            "3  Review potential interactions, especially Osel...  \n",
            "4  Monitor for side effects of SSRI. Caution with...  \n",
            "\n",
            "[5 rows x 36 columns]\n",
            "\n",
            "Data Types:\n",
            "Patient_ID                       int64\n",
            "Age                              int64\n",
            "Gender                          object\n",
            "Blood_Group                     object\n",
            "Weight_kg                      float64\n",
            "Has_Fever                        int64\n",
            "Has_Cough                        int64\n",
            "Has_Fatigue                      int64\n",
            "Has_Pain                         int64\n",
            "Has_Hypertension                 int64\n",
            "Has_Diabetes                     int64\n",
            "Temperature_C                  float64\n",
            "Heart_Rate                       int64\n",
            "BP_Systolic                      int64\n",
            "WBC_Count                      float64\n",
            "Glucose_Level                    int64\n",
            "Predicted_Disease               object\n",
            "Disease_Causes                  object\n",
            "Medicine_1                      object\n",
            "Dosage_1                        object\n",
            "Frequency_1                     object\n",
            "Duration_1                      object\n",
            "Instructions_1                  object\n",
            "Medicine_2                      object\n",
            "Dosage_2                        object\n",
            "Frequency_2                     object\n",
            "Duration_2                      object\n",
            "Instructions_2                  object\n",
            "Medicine_3                      object\n",
            "Dosage_3                        object\n",
            "Frequency_3                     object\n",
            "Duration_3                      object\n",
            "Instructions_3                  object\n",
            "Personalized_Health_Tips        object\n",
            "Polypharmacy_Risk               object\n",
            "Polypharmacy_Recommendation     object\n",
            "dtype: object\n",
            "\n",
            "Missing Values Per Column:\n",
            "Medicine_1         1084\n",
            "Dosage_1           1084\n",
            "Frequency_1        1084\n",
            "Duration_1         1084\n",
            "Instructions_1     1084\n",
            "Medicine_2         2227\n",
            "Dosage_2           2227\n",
            "Frequency_2        2227\n",
            "Duration_2         2227\n",
            "Instructions_2     2227\n",
            "Medicine_3        11488\n",
            "Dosage_3          11488\n",
            "Frequency_3       11488\n",
            "Duration_3        11488\n",
            "Instructions_3    11488\n",
            "dtype: int64\n",
            "\n",
            "Handling missing values...\n",
            "\n",
            "Identified 14 target columns: ['Predicted_Disease', 'Medicine_1', 'Dosage_1', 'Frequency_1', 'Duration_1', 'Medicine_2', 'Dosage_2', 'Frequency_2', 'Duration_2', 'Medicine_3', 'Dosage_3', 'Frequency_3', 'Duration_3', 'Polypharmacy_Risk']\n",
            "\n",
            "Features data shape (X): (15000, 22)\n",
            "Target data shape (y_ml): (15000, 14)\n",
            "\n",
            "Identified 8 categorical features: ['Gender', 'Blood_Group', 'Disease_Causes', 'Instructions_1', 'Instructions_2', 'Instructions_3', 'Personalized_Health_Tips', 'Polypharmacy_Recommendation']\n",
            "Identified 14 numerical features: ['Patient_ID', 'Age', 'Weight_kg', 'Has_Fever', 'Has_Cough', 'Has_Fatigue', 'Has_Pain', 'Has_Hypertension', 'Has_Diabetes', 'Temperature_C', 'Heart_Rate', 'BP_Systolic', 'WBC_Count', 'Glucose_Level']\n",
            "\n",
            "Basic statistics for numerical features:\n",
            "         Patient_ID           Age     Weight_kg     Has_Fever     Has_Cough  \\\n",
            "count  15000.000000  15000.000000  15000.000000  15000.000000  15000.000000   \n",
            "mean    7500.500000     44.790667     74.927433      0.252267      0.333200   \n",
            "std     4330.271354     14.518383     15.012800      0.434328      0.471373   \n",
            "min        1.000000     18.000000     22.600000      0.000000      0.000000   \n",
            "25%     3750.750000     35.000000     64.800000      0.000000      0.000000   \n",
            "50%     7500.500000     45.000000     75.000000      0.000000      0.000000   \n",
            "75%    11250.250000     55.000000     85.000000      1.000000      1.000000   \n",
            "max    15000.000000     90.000000    131.400000      1.000000      1.000000   \n",
            "\n",
            "        Has_Fatigue      Has_Pain  Has_Hypertension  Has_Diabetes  \\\n",
            "count  15000.000000  15000.000000      15000.000000  15000.000000   \n",
            "mean       0.506467      0.519333          0.202200      0.146000   \n",
            "std        0.499975      0.499643          0.401654      0.353118   \n",
            "min        0.000000      0.000000          0.000000      0.000000   \n",
            "25%        0.000000      0.000000          0.000000      0.000000   \n",
            "50%        1.000000      1.000000          0.000000      0.000000   \n",
            "75%        1.000000      1.000000          0.000000      0.000000   \n",
            "max        1.000000      1.000000          1.000000      1.000000   \n",
            "\n",
            "       Temperature_C    Heart_Rate   BP_Systolic     WBC_Count  Glucose_Level  \n",
            "count   15000.000000  15000.000000  15000.000000  15000.000000   15000.000000  \n",
            "mean       37.247527     77.200533    122.353067      8.335633     102.394267  \n",
            "std         0.852433     12.020697     13.022692      3.012926      30.088487  \n",
            "min        34.900000     40.000000     72.000000      3.000000      60.000000  \n",
            "25%        36.600000     68.000000    113.000000      6.300000      83.000000  \n",
            "50%        37.100000     76.000000    121.000000      7.900000      98.000000  \n",
            "75%        37.700000     86.000000    130.000000      9.800000     113.000000  \n",
            "max        40.500000    119.000000    178.000000     21.400000     245.000000  \n",
            "\n",
            "Class distribution for Predicted_Disease:\n",
            "Predicted_Disease\n",
            "Anxiety Disorder           1222\n",
            "Diabetes Type 2            1195\n",
            "Urinary Tract Infection    1195\n",
            "Influenza                  1182\n",
            "Bacterial Pneumonia        1179\n",
            "GERD                       1174\n",
            "Hypothyroidism             1143\n",
            "Hypertension               1143\n",
            "Asthma Exacerbation        1138\n",
            "Osteoarthritis             1132\n",
            "Common Cold                1121\n",
            "Migraine                   1092\n",
            "Healthy                    1084\n",
            "Name: count, dtype: int64\n",
            "Class imbalance ratio (max/min): 1.13\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Data Preparation & Initial Exploration\n",
        "\n",
        "print(\"\\n--- Data Preparation & Exploratory Analysis ---\")\n",
        "\n",
        "# Load the data (assuming CSV files are already uploaded to the Colab environment)\n",
        "try:\n",
        "    # Load main dataset\n",
        "    data = pd.read_csv('/content/Synthetic_Medical_Dataset_v2.csv')  # Update with your actual filename\n",
        "    print(f\"Loaded main dataset with {data.shape[0]} rows and {data.shape[1]} columns\")\n",
        "\n",
        "    # Load disease-symptom mappings if available\n",
        "    try:\n",
        "        mapping_data = pd.read_csv('disease_mappings.csv')  # Update with your actual filename\n",
        "        print(f\"Loaded mappings data with {mapping_data.shape[0]} rows and {mapping_data.shape[1]} columns\")\n",
        "    except Exception as e:\n",
        "        print(f\"Note: No separate mappings file loaded: {e}\")\n",
        "        mapping_data = None\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Dataset file not found. Please upload the dataset files.\")\n",
        "    raise\n",
        "\n",
        "# Display dataset information\n",
        "print(\"\\nData Overview:\")\n",
        "print(data.head())\n",
        "print(\"\\nData Types:\")\n",
        "print(data.dtypes)\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = data.isnull().sum()\n",
        "if missing_values.sum() > 0:\n",
        "    print(\"\\nMissing Values Per Column:\")\n",
        "    print(missing_values[missing_values > 0])\n",
        "\n",
        "    # Handle missing values\n",
        "    print(\"\\nHandling missing values...\")\n",
        "    # Numeric columns: fill with median\n",
        "    numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
        "    for col in numeric_cols:\n",
        "        if data[col].isnull().sum() > 0:\n",
        "            data[col] = data[col].fillna(data[col].median())\n",
        "\n",
        "    # Categorical columns: fill with mode\n",
        "    cat_cols = data.select_dtypes(include=['object', 'category']).columns\n",
        "    for col in cat_cols:\n",
        "        if data[col].isnull().sum() > 0:\n",
        "            data[col] = data[col].fillna(data[col].mode()[0])\n",
        "else:\n",
        "    print(\"\\nNo missing values found in the dataset.\")\n",
        "\n",
        "# Separate features and target variables\n",
        "# Identify target columns (modify based on your dataset structure)\n",
        "target_cols = ['Predicted_Disease']\n",
        "if 'Medicine_1' in data.columns:\n",
        "    target_cols.extend(['Medicine_1', 'Dosage_1', 'Frequency_1', 'Duration_1'])\n",
        "if 'Medicine_2' in data.columns:\n",
        "    target_cols.extend(['Medicine_2', 'Dosage_2', 'Frequency_2', 'Duration_2'])\n",
        "if 'Medicine_3' in data.columns:\n",
        "    target_cols.extend(['Medicine_3', 'Dosage_3', 'Frequency_3', 'Duration_3'])\n",
        "if 'Polypharmacy_Risk' in data.columns:\n",
        "    target_cols.append('Polypharmacy_Risk')\n",
        "\n",
        "print(f\"\\nIdentified {len(target_cols)} target columns: {target_cols}\")\n",
        "\n",
        "# Split data into features (X) and targets (y)\n",
        "X = data.drop(columns=target_cols)\n",
        "y_ml = data[target_cols]\n",
        "\n",
        "print(f\"\\nFeatures data shape (X): {X.shape}\")\n",
        "print(f\"Target data shape (y_ml): {y_ml.shape}\")\n",
        "\n",
        "# Identify categorical and numerical features\n",
        "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "print(f\"\\nIdentified {len(categorical_features)} categorical features: {categorical_features}\")\n",
        "print(f\"Identified {len(numerical_features)} numerical features: {numerical_features}\")\n",
        "\n",
        "# Basic statistics for numerical features\n",
        "print(\"\\nBasic statistics for numerical features:\")\n",
        "print(X[numerical_features].describe())\n",
        "\n",
        "# Class distribution for primary target\n",
        "if 'Predicted_Disease' in y_ml.columns:\n",
        "    print(\"\\nClass distribution for Predicted_Disease:\")\n",
        "    disease_counts = y_ml['Predicted_Disease'].value_counts()\n",
        "    print(disease_counts)\n",
        "\n",
        "    # Check for class imbalance\n",
        "    class_imbalance = disease_counts.max() / disease_counts.min()\n",
        "    print(f\"Class imbalance ratio (max/min): {class_imbalance:.2f}\")\n",
        "    if class_imbalance > 10:\n",
        "        print(\"Warning: Significant class imbalance detected.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYWzeSMEY9Xf",
        "outputId": "213ae650-d8ff-4389-c96e-0415bf34387b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Encoding ML Target Variables (y_ml) ---\n",
            "Encoded 'Predicted_Disease'. Classes: 13\n",
            "Encoded 'Frequency_1'. Classes: 6\n",
            "Encoded 'Duration_1'. Classes: 7\n",
            "Encoded 'Frequency_2'. Classes: 7\n",
            "Encoded 'Duration_2'. Classes: 6\n",
            "Encoded 'Medicine_3'. Classes: 3\n",
            "Encoded 'Dosage_3'. Classes: 3\n",
            "Encoded 'Frequency_3'. Classes: 3\n",
            "Encoded 'Duration_3'. Classes: 2\n",
            "Encoded 'Polypharmacy_Risk'. Classes: 3\n",
            "\n",
            "Encoded 14 non-constant target columns for the ML model.\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Preprocessing - Target Variables (y_ml) using LabelEncoder\n",
        "\n",
        "print(\"\\n--- Encoding ML Target Variables (y_ml) ---\")\n",
        "# y_ml now contains only non-constant columns identified in Cell 3\n",
        "\n",
        "target_encoders = {}\n",
        "y_ml_encoded = pd.DataFrame(index=y_ml.index) # Will use the filtered y_ml\n",
        "\n",
        "if y_ml.empty:\n",
        "    print(\"Warning: y_ml is empty. No target variables to encode.\")\n",
        "else:\n",
        "    for col in y_ml.columns: # Iterates over the filtered, non-constant columns\n",
        "        le = LabelEncoder()\n",
        "        try:\n",
        "            # Ensure consistent type (string) for encoder, handle potential mixed types gracefully\n",
        "            y_ml_encoded[col] = le.fit_transform(y_ml[col].astype(str))\n",
        "            target_encoders[col] = le\n",
        "            # Print info for primary target and low-cardinality targets\n",
        "            if col == 'Predicted_Disease' or len(le.classes_) < 10:\n",
        "                print(f\"Encoded '{col}'. Classes: {len(le.classes_)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error encoding column '{col}': {e}\")\n",
        "            # Optionally decide how to handle error: skip column, raise error, etc.\n",
        "\n",
        "    print(f\"\\nEncoded {len(target_encoders)} non-constant target columns for the ML model.\")\n",
        "    # Display head of encoded data for verification\n",
        "    # print(\"\\nHead of encoded ML targets (y_ml_encoded):\")\n",
        "    # print(y_ml_encoded.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8bktZalZANO",
        "outputId": "ab45aafe-6b21-4881-f2c0-e29bb4f57d11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Defining Preprocessing Pipeline for Input Features (X) with Feature Engineering ---\n",
            "Adding engineered features...\n",
            "Created 35 enhanced engineered features\n",
            " - Numerical features: 49\n",
            " - Categorical features to encode: ['Gender', 'Blood_Group', 'Age_Group']\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Preprocessing - Input Features (X) with Feature Engineering\n",
        "\n",
        "print(\"\\n--- Defining Preprocessing Pipeline for Input Features (X) with Feature Engineering ---\")\n",
        "\n",
        "# Feature Engineering - Create new features from existing ones\n",
        "print(\"Adding engineered features...\")\n",
        "\n",
        "# Create interaction features between binary symptoms\n",
        "X['fever_cough'] = X['Has_Fever'] * X['Has_Cough']\n",
        "X['fever_fatigue'] = X['Has_Fever'] * X['Has_Fatigue']\n",
        "X['pain_fatigue'] = X['Has_Pain'] * X['Has_Fatigue']\n",
        "X['hypertension_diabetes'] = X['Has_Hypertension'] * X['Has_Diabetes']\n",
        "\n",
        "# Create age groups\n",
        "X['Age_Group'] = pd.cut(X['Age'],\n",
        "                       bins=[0, 18, 35, 50, 65, 100],\n",
        "                       labels=['Child', 'Young_Adult', 'Adult', 'Senior', 'Elderly'])\n",
        "\n",
        "# Create BMI approximation\n",
        "X['BMI'] = X['Weight_kg'] / ((X['Height'] if 'Height' in X.columns else X['Weight_kg']/30)**2)\n",
        "\n",
        "# Vital sign combinations\n",
        "X['BP_HR_Ratio'] = X['BP_Systolic'] / X['Heart_Rate']\n",
        "X['Fever_Severity'] = X['Temperature_C'] - 37.0\n",
        "\n",
        "# Basic disease patterns\n",
        "X['GERD_Pattern'] = ((X['Age'] > 40) & (X['Has_Pain'] == 1) & (X['Has_Cough'] == 0)).astype(int)\n",
        "X['Migraine_Pattern'] = ((X['Age'] < 50) & (X['Has_Pain'] == 1) & (X['Has_Fever'] == 0)).astype(int)\n",
        "X['Osteo_Pattern'] = ((X['Age'] > 55) & (X['Has_Pain'] == 1) & (X['Weight_kg'] > 75)).astype(int)\n",
        "\n",
        "# ADVANCED DISEASE-SPECIFIC PATTERNS - Much more granular and focused on problem areas\n",
        "X['GERD_Advanced'] = ((X['Age'] > 40) & (X['Has_Pain'] == 1) & (X['Has_Cough'] == 0) &\n",
        "                     (X['BP_Systolic'] < 130) & (X['Heart_Rate'] < 80) &\n",
        "                     (X['Has_Fatigue'] == 0)).astype(int)\n",
        "\n",
        "X['Migraine_Advanced'] = ((X['Age'] < 50) & (X['Has_Pain'] == 1) & (X['Has_Fever'] == 0) &\n",
        "                         (X['Heart_Rate'] > 70) & (X['Has_Fatigue'] == 1) &\n",
        "                         (X['Temperature_C'] < 37.2)).astype(int)\n",
        "\n",
        "X['Osteo_Advanced'] = ((X['Age'] > 55) & (X['Has_Pain'] == 1) & (X['Weight_kg'] > 75) &\n",
        "                      (X['Has_Hypertension'] == 0) & (X['Has_Fever'] == 0) &\n",
        "                      (X['BP_Systolic'] > 110)).astype(int)\n",
        "\n",
        "X['Cold_Advanced'] = ((X['Has_Fever'] == 1) & (X['Has_Cough'] == 1) &\n",
        "                     (X['Temperature_C'] < 38.5) & (X['Temperature_C'] > 37.0) &\n",
        "                     (X['WBC_Count'] < 10) & (X['Has_Fatigue'] == 1)).astype(int)\n",
        "\n",
        "# EXTREME SPECIFICITY FOR PROBLEM CLASSES\n",
        "X['GERD_Specific'] = ((X['Age'] > 40) & (X['Has_Pain'] == 1) & (X['Has_Cough'] == 0) &\n",
        "                      (X['BP_Systolic'] < 130) & (X['Temperature_C'] < 37.0) &\n",
        "                      (X['WBC_Count'] < 8.0) & (X['Has_Hypertension'] == 0) &\n",
        "                      (X['Has_Diabetes'] == 0)).astype(int)\n",
        "\n",
        "X['Migraine_Specific'] = ((X['Age'] < 50) & (X['Has_Pain'] == 1) & (X['Has_Fever'] == 0) &\n",
        "                          (X['Heart_Rate'] > 70) & (X['Heart_Rate'] < 100) &\n",
        "                          (X['Has_Fatigue'] == 1) & (X['BP_Systolic'] < 130) &\n",
        "                          (X['Has_Hypertension'] == 0)).astype(int)\n",
        "\n",
        "X['Osteo_Specific'] = ((X['Age'] > 55) & (X['Has_Pain'] == 1) & (X['Weight_kg'] > 75) &\n",
        "                       (X['Has_Fever'] == 0) & (X['Has_Cough'] == 0) &\n",
        "                       (X['Has_Fatigue'] == 0) & (X['WBC_Count'] < 9.0) &\n",
        "                       (X['BP_Systolic'] > 120)).astype(int)\n",
        "\n",
        "X['Cold_Specific'] = ((X['Has_Fever'] == 1) & (X['Has_Cough'] == 1) &\n",
        "                      (X['Temperature_C'] < 38.0) & (X['Temperature_C'] > 37.2) &\n",
        "                      (X['WBC_Count'] < 9.0) & (X['WBC_Count'] > 5.0) &\n",
        "                      (X['Has_Fatigue'] == 1) & (X['Has_Pain'] == 0)).astype(int)\n",
        "\n",
        "# TRIPLE COMBINATIONS - More complex interactions\n",
        "X['Fever_Cough_Fatigue'] = X['Has_Fever'] * X['Has_Cough'] * X['Has_Fatigue']\n",
        "X['Pain_Fever_Fatigue'] = X['Has_Pain'] * X['Has_Fever'] * X['Has_Fatigue']\n",
        "X['Pain_Cough_Fatigue'] = X['Has_Pain'] * X['Has_Cough'] * X['Has_Fatigue']\n",
        "X['Vital_Interaction'] = (X['Temperature_C'] * X['Heart_Rate'] * X['BP_Systolic']) / 1000\n",
        "\n",
        "# MATHEMATICAL TRANSFORMATIONS - Non-linear relationships\n",
        "X['Temp_Squared'] = (X['Temperature_C'] - 37.0) ** 2\n",
        "X['BP_Squared'] = ((X['BP_Systolic'] - 120) / 10) ** 2\n",
        "X['HR_Squared'] = ((X['Heart_Rate'] - 75) / 10) ** 2\n",
        "X['WBC_Squared'] = ((X['WBC_Count'] - 7.5) / 2) ** 2\n",
        "X['Glucose_Scaled'] = (X['Glucose_Level'] - 100) / 10\n",
        "\n",
        "# SYMPTOM COMBINATIONS BY AGE\n",
        "X['Young_With_Fever'] = ((X['Age'] < 35) & (X['Has_Fever'] == 1)).astype(int)\n",
        "X['Senior_With_Pain'] = ((X['Age'] > 65) & (X['Has_Pain'] == 1)).astype(int)\n",
        "X['Middle_With_Fatigue'] = ((X['Age'] > 35) & (X['Age'] < 65) & (X['Has_Fatigue'] == 1)).astype(int)\n",
        "\n",
        "# Blood count indicators - Specific ranges relevant to infections vs other conditions\n",
        "X['High_WBC'] = (X['WBC_Count'] > 10.0).astype(int)\n",
        "X['Low_WBC'] = (X['WBC_Count'] < 5.0).astype(int)\n",
        "X['Normal_WBC'] = ((X['WBC_Count'] >= 5.0) & (X['WBC_Count'] <= 10.0)).astype(int)\n",
        "\n",
        "# CONDITIONAL FEATURES - Disease-discriminating conditions\n",
        "X['Likely_Infection'] = ((X['Has_Fever'] == 1) & (X['WBC_Count'] > 9.0) &\n",
        "                          (X['Temperature_C'] > 37.5)).astype(int)\n",
        "X['Likely_Chronic'] = ((X['Has_Fever'] == 0) & (X['Has_Fatigue'] == 1) &\n",
        "                       (X['WBC_Count'] < 9.0)).astype(int)\n",
        "X['Likely_Acute'] = ((X['Has_Fever'] == 1) | (X['Has_Pain'] == 1)) & (X['Has_Fatigue'] == 0)\n",
        "\n",
        "# Count total symptoms as a feature (symptom burden)\n",
        "X['Symptom_Count'] = (X['Has_Fever'] + X['Has_Cough'] + X['Has_Fatigue'] +\n",
        "                     X['Has_Pain'] + X['Has_Hypertension'] + X['Has_Diabetes'])\n",
        "\n",
        "print(f\"Created {35} enhanced engineered features\")\n",
        "\n",
        "# Define column types based on the input_features and new engineered features\n",
        "numerical_features = [\n",
        "    'Age', 'Weight_kg', 'Temperature_C', 'Heart_Rate', 'BP_Systolic',\n",
        "    'WBC_Count', 'Glucose_Level',\n",
        "    # Binary flags\n",
        "    'Has_Fever', 'Has_Cough', 'Has_Fatigue', 'Has_Pain', 'Has_Hypertension', 'Has_Diabetes',\n",
        "    # Basic engineered features\n",
        "    'fever_cough', 'fever_fatigue', 'pain_fatigue', 'hypertension_diabetes',\n",
        "    'BMI', 'BP_HR_Ratio', 'Fever_Severity',\n",
        "    'GERD_Pattern', 'Migraine_Pattern', 'Osteo_Pattern',\n",
        "    # Advanced pattern features\n",
        "    'GERD_Advanced', 'Migraine_Advanced', 'Osteo_Advanced', 'Cold_Advanced',\n",
        "    'GERD_Specific', 'Migraine_Specific', 'Osteo_Specific', 'Cold_Specific',\n",
        "    # Complex interactions\n",
        "    'Fever_Cough_Fatigue', 'Pain_Fever_Fatigue', 'Pain_Cough_Fatigue', 'Vital_Interaction',\n",
        "    # Mathematical transformations\n",
        "    'Temp_Squared', 'BP_Squared', 'HR_Squared', 'WBC_Squared', 'Glucose_Scaled',\n",
        "    # Age-symptom combinations\n",
        "    'Young_With_Fever', 'Senior_With_Pain', 'Middle_With_Fatigue',\n",
        "    # Blood count indicators\n",
        "    'High_WBC', 'Low_WBC', 'Normal_WBC',\n",
        "    # Conditional features\n",
        "    'Likely_Infection', 'Likely_Chronic', 'Symptom_Count'\n",
        "]\n",
        "\n",
        "categorical_features = ['Gender', 'Blood_Group', 'Age_Group']\n",
        "\n",
        "print(f\" - Numerical features: {len(numerical_features)}\")\n",
        "print(f\" - Categorical features to encode: {categorical_features}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkPrPs_vsS0k",
        "outputId": "bbd805d8-5211-4888-cb68-e9654f947322"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Creating Train-Test Split ---\n",
            "Training set: 12000 samples\n",
            "Testing set: 3000 samples\n",
            "X_train shape: (12000, 60)\n",
            "y_train_encoded_df shape: (12000, 14)\n",
            "X_test shape: (3000, 60)\n",
            "y_test_encoded_df shape: (3000, 14)\n",
            "Found 14 target columns with varied values for model training\n"
          ]
        }
      ],
      "source": [
        "# Cell 5.5: Train-Test Split\n",
        "\n",
        "print(\"\\n--- Creating Train-Test Split ---\")\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_ml_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Convert y_train and y_test to DataFrames with the same column names as y_ml_encoded\n",
        "y_train_encoded_df = pd.DataFrame(y_train, columns=y_ml_encoded.columns)\n",
        "y_test_encoded_df = pd.DataFrame(y_test, columns=y_ml_encoded.columns)\n",
        "\n",
        "# Define target columns for model training\n",
        "ml_target_cols = list(y_ml_encoded.columns)\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Testing set: {X_test.shape[0]} samples\")\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train_encoded_df shape: {y_train_encoded_df.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test_encoded_df shape: {y_test_encoded_df.shape}\")\n",
        "\n",
        "# Check for columns with only one unique value in training set\n",
        "varied_cols_in_train = []\n",
        "for col in y_train_encoded_df.columns:\n",
        "    if len(y_train_encoded_df[col].unique()) > 1:\n",
        "        varied_cols_in_train.append(col)\n",
        "    else:\n",
        "        print(f\"Warning: Column '{col}' has only one unique value in the training set and will be ignored for modeling.\")\n",
        "\n",
        "print(f\"Found {len(varied_cols_in_train)} target columns with varied values for model training\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-6M6afjZBJn",
        "outputId": "f560996d-e89d-44f8-e260-05341ac6c4af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Applying Feature Engineering to Train/Test Sets ---\n",
            "Added 12 engineered features to both training and test sets\n",
            "Updated categorical features list: ['Gender', 'Blood_Group', 'Age_Group', 'Age_Group']\n",
            "Preprocessor updated with new features\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: Feature Engineering - Apply AFTER Train-Test Split\n",
        "\n",
        "print(\"\\n--- Applying Feature Engineering to Train/Test Sets ---\")\n",
        "\n",
        "# Apply the same feature engineering to both train and test sets\n",
        "for dataset in [X_train, X_test]:\n",
        "    # Create interaction features between symptoms\n",
        "    dataset['fever_cough'] = dataset['Has_Fever'] * dataset['Has_Cough']\n",
        "    dataset['fever_fatigue'] = dataset['Has_Fever'] * dataset['Has_Fatigue']\n",
        "    dataset['pain_fatigue'] = dataset['Has_Pain'] * dataset['Has_Fatigue']\n",
        "\n",
        "    # Handle possible missing columns with safe checks\n",
        "    has_hypertension = 'Has_Hypertension' in dataset.columns\n",
        "    has_diabetes = 'Has_Diabetes' in dataset.columns\n",
        "    if has_hypertension and has_diabetes:\n",
        "        dataset['hypertension_diabetes'] = dataset['Has_Hypertension'] * dataset['Has_Diabetes']\n",
        "\n",
        "    # Create age groups\n",
        "    dataset['Age_Group'] = pd.cut(dataset['Age'],\n",
        "                                bins=[0, 18, 35, 50, 65, 100],\n",
        "                                labels=['Child', 'Young_Adult', 'Adult', 'Senior', 'Elderly'])\n",
        "\n",
        "    # BMI calculation with safe division\n",
        "    height_col = 'Height_cm' if 'Height_cm' in dataset.columns else 'Height' if 'Height' in dataset.columns else None\n",
        "    if height_col:\n",
        "        # Convert height to meters and calculate BMI normally\n",
        "        height_m = dataset[height_col] / 100\n",
        "        dataset['BMI'] = dataset['Weight_kg'] / (height_m ** 2)\n",
        "    else:\n",
        "        # Approximation if no height column exists\n",
        "        dataset['BMI'] = dataset['Weight_kg'] / ((dataset['Weight_kg'] / 30) ** 2)\n",
        "\n",
        "    # Vital sign combinations (with safe division)\n",
        "    dataset['BP_HR_Ratio'] = dataset['BP_Systolic'] / dataset['Heart_Rate'].replace(0, 1)\n",
        "    dataset['Fever_Severity'] = dataset['Temperature_C'] - 37.0\n",
        "\n",
        "    # Disease-specific pattern indicators for problematic classes\n",
        "    dataset['GERD_Pattern'] = ((dataset['Age'] > 40) &\n",
        "                             (dataset['Has_Pain'] == 1) &\n",
        "                             (dataset['Has_Cough'] == 0)).astype(int)\n",
        "\n",
        "    dataset['Migraine_Pattern'] = ((dataset['Age'] < 50) &\n",
        "                                 (dataset['Has_Pain'] == 1) &\n",
        "                                 (dataset['Has_Fever'] == 0)).astype(int)\n",
        "\n",
        "    dataset['Osteo_Pattern'] = ((dataset['Age'] > 55) &\n",
        "                              (dataset['Has_Pain'] == 1) &\n",
        "                              (dataset['Weight_kg'] > 75)).astype(int)\n",
        "\n",
        "    dataset['Cold_Pattern'] = ((dataset['Has_Fever'] == 1) &\n",
        "                             (dataset['Has_Cough'] == 1) &\n",
        "                             (dataset['Temperature_C'] < 38.5)).astype(int)\n",
        "\n",
        "# Update categorical features list to include new categorical feature\n",
        "categorical_features.append('Age_Group')\n",
        "\n",
        "print(f\"Added 12 engineered features to both training and test sets\")\n",
        "print(f\"Updated categorical features list: {categorical_features}\")\n",
        "\n",
        "# Recreate preprocessor with updated categorical features list\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), [col for col in X_train.columns if col not in categorical_features]),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "print(\"Preprocessor updated with new features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdwbfRuoZC-v",
        "outputId": "83996b31-1cf4-4f0c-d8dc-590a06c1079c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Creating Mappings for Textual Outputs ---\n",
            "Defined 6 text output columns for mapping\n",
            "Created mappings for 13 diseases found in training data.\n",
            "\n",
            "Example mapping for 'Urinary Tract Infection':\n",
            "{\n",
            "  \"Disease_Causes\": \"Bacterial infection (commonly E. coli).\",\n",
            "  \"Instructions_1\": \"Complete full course, drink plenty of water.\",\n",
            "  \"Instructions_2\": \"For pain relief only, turns urine orange.\",\n",
            "  \"Instructions_3\": \"For kidney protection/BP.\",\n",
            "  \"Personalized_Health_Tips\": \"Wipe front to back, urinate after intercourse, stay hydrated.\",\n",
            "  \"Polypharmacy_Recommendation\": \"Check for sulfa allergy. Stay hydrated.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Cell 6.5: Create Mappings for Textual Outputs (from Original Data)\n",
        "\n",
        "print(\"\\n--- Creating Mappings for Textual Outputs ---\")\n",
        "\n",
        "# Define the mapping target columns (text fields we want to include in mappings)\n",
        "mapping_target_cols = [\n",
        "    'Disease_Causes',\n",
        "    'Instructions_1',\n",
        "    'Instructions_2',\n",
        "    'Instructions_3',\n",
        "    'Personalized_Health_Tips',\n",
        "    'Polypharmacy_Recommendation'\n",
        "]\n",
        "\n",
        "print(f\"Defined {len(mapping_target_cols)} text output columns for mapping\")\n",
        "\n",
        "# Use original data to create mappings (using only columns found in training data)\n",
        "disease_to_text_mappings = {}\n",
        "\n",
        "# Extract rows from the training indices to avoid data leakage\n",
        "train_indices = X_train.index\n",
        "mapping_train = data.loc[train_indices]\n",
        "\n",
        "# Get unique disease-text combinations from the training set\n",
        "try:\n",
        "    # Keep only the columns we need for mapping\n",
        "    mapping_cols = ['Predicted_Disease'] + mapping_target_cols\n",
        "    available_cols = [col for col in mapping_cols if col in data.columns]\n",
        "\n",
        "    # Check which columns were found and which are missing\n",
        "    missing_cols = set(mapping_cols) - set(available_cols)\n",
        "    if missing_cols:\n",
        "        print(f\"Warning: Could not find these columns: {missing_cols}\")\n",
        "\n",
        "    mapping_df_unique = mapping_train[available_cols].drop_duplicates(subset=['Predicted_Disease'])\n",
        "\n",
        "    # Create a dictionary mapping Disease -> Dictionary_of_Texts\n",
        "    for idx, row in mapping_df_unique.iterrows():\n",
        "        disease = row['Predicted_Disease']\n",
        "        disease_texts = {col: row[col] for col in available_cols if col != 'Predicted_Disease'}\n",
        "        disease_to_text_mappings[disease] = disease_texts\n",
        "\n",
        "    print(f\"Created mappings for {len(disease_to_text_mappings)} diseases found in training data.\")\n",
        "\n",
        "    # Example output - show first disease mapping\n",
        "    first_disease = list(disease_to_text_mappings.keys())[0]\n",
        "    print(f\"\\nExample mapping for '{first_disease}':\")\n",
        "    print(json.dumps(disease_to_text_mappings[first_disease], indent=2))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error creating disease mappings: {e}\")\n",
        "    disease_to_text_mappings = {} # Empty dictionary as fallback\n",
        "    print(\"Using empty mappings as fallback.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1Iw1DtEmsNN",
        "outputId": "076959b2-71d7-4cb8-fb4a-66c26fd9f419"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Ultra-Aggressive Class Balancing ---\n",
            "Focusing on ultra-aggressive improvement for: GERD, Migraine, Osteoarthritis, Common Cold\n",
            "Increased weight for Anxiety Disorder (code 0) to 5.0\n",
            "Increased weight for Common Cold (code 3) to 15.0\n",
            "Increased weight for GERD (code 5) to 15.0\n",
            "Increased weight for Healthy (code 6) to 5.0\n",
            "Increased weight for Hypothyroidism (code 8) to 5.0\n",
            "Increased weight for Migraine (code 10) to 15.0\n",
            "Increased weight for Osteoarthritis (code 11) to 15.0\n",
            "Created extreme custom class weights for 13 disease classes\n",
            "Created sample weights array with shape (12000,)\n"
          ]
        }
      ],
      "source": [
        "# Cell 6.6: Create even more aggressive class weights for problem classes\n",
        "\n",
        "print(\"\\n--- Ultra-Aggressive Class Balancing ---\")\n",
        "\n",
        "# Identify problematic disease classes from previous run\n",
        "problematic_classes = ['GERD', 'Migraine', 'Osteoarthritis', 'Common Cold']\n",
        "medium_classes = ['Healthy', 'Hypothyroidism', 'Anxiety Disorder']\n",
        "print(f\"Focusing on ultra-aggressive improvement for: {', '.join(problematic_classes)}\")\n",
        "\n",
        "# Calculate class weights for the Predicted_Disease column\n",
        "from collections import Counter\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Get disease labels and compute weights\n",
        "if 'Predicted_Disease' in y_train_encoded_df.columns:\n",
        "    disease_counts = Counter(y_train_encoded_df['Predicted_Disease'])\n",
        "    unique_classes = sorted(disease_counts.keys())\n",
        "\n",
        "    # ULTRA-aggressive oversampling weights for problematic classes\n",
        "    custom_class_weights = {i: 1.0 for i in unique_classes}\n",
        "    for disease_code in unique_classes:\n",
        "        # Decode to get disease name\n",
        "        disease_name = target_encoders['Predicted_Disease'].inverse_transform([disease_code])[0]\n",
        "        if disease_name in problematic_classes:\n",
        "            # EXTREME weight increase (15x) for problematic classes\n",
        "            custom_class_weights[disease_code] = 15.0\n",
        "            print(f\"Increased weight for {disease_name} (code {disease_code}) to 15.0\")\n",
        "        elif disease_name in medium_classes:\n",
        "            # Significant weight increase (5x) for medium-performing classes\n",
        "            custom_class_weights[disease_code] = 5.0\n",
        "            print(f\"Increased weight for {disease_name} (code {disease_code}) to 5.0\")\n",
        "\n",
        "    print(f\"Created extreme custom class weights for {len(unique_classes)} disease classes\")\n",
        "\n",
        "    # Save weights for model training\n",
        "    sample_weights = np.ones(len(y_train_encoded_df))\n",
        "    for i, val in enumerate(y_train_encoded_df['Predicted_Disease']):\n",
        "        sample_weights[i] = custom_class_weights[val]\n",
        "\n",
        "    print(f\"Created sample weights array with shape {sample_weights.shape}\")\n",
        "else:\n",
        "    print(\"Warning: 'Predicted_Disease' not found in encoded training data\")\n",
        "    sample_weights = None"
      ]
    },
    {
      "source": [
        "!pip install scikit-optimize"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ92ZN5nNKSL",
        "outputId": "b241245f-7404-47a9-e82e-4eb20b8ccfde"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-25.1.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.1.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-25.1.0 scikit-optimize-0.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz6CTZGcPIK8",
        "outputId": "151667a8-a610-4a11-c6ac-e952d5102748"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178,
          "referenced_widgets": [
            "a2bdbdc732f641d8bd6f74744d361677",
            "4640d3fc651341b29d983932c86e93d2",
            "2aaf03156f0c4771896ab9b63028cdb4",
            "643ca826110d41c6b28dcfed9615c747",
            "6be9bab4174b4d639cc13b6c524a5eb6",
            "a027fe9693664a06bf9422600cb907fa",
            "66d1692af5fc414cb90e4a1237d9da94",
            "ac47d83fa3c44ee5bee777fd97e403e0",
            "711adb47a45b4dc496f99b106d348e6d",
            "bc2f286d425543ad8167bd01e13e5f70",
            "d41be1433a7a405ab05a51aabe89b575"
          ]
        },
        "id": "utYsXZjRZEsG",
        "outputId": "599d0ca0-031e-48ec-cee3-c33430106fd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training ML Model with Bayesian Optimization (Optimized) ---\n",
            "Starting Bayesian optimization with improved efficiency...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Bayesian Optimization Progress:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2bdbdc732f641d8bd6f74744d361677"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best CV accuracy: 0.6857\n",
            "Best parameters: OrderedDict([('colsample_bytree', 0.7230311876559942), ('learning_rate', 0.0534226888747111), ('max_depth', 14), ('min_child_samples', 10), ('n_estimators', 368), ('num_leaves', 71), ('reg_alpha', 0.022435271778548954), ('reg_lambda', 0.05489139072630632), ('subsample', 0.6913389933109518)])\n",
            "Optimized model training complete\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: Optimized LightGBM with Bayesian Optimization and Progress Bar\n",
        "\n",
        "print(\"\\n--- Training ML Model with Bayesian Optimization (Optimized) ---\")\n",
        "\n",
        "# Import Bayesian optimization with early stopping\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Integer, Categorical\n",
        "from skopt.callbacks import DeltaYStopper\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "\n",
        "# Define more efficient search space\n",
        "search_space = {\n",
        "    'learning_rate': Real(0.01, 0.1, prior='log-uniform'),    # Higher, narrower range\n",
        "    'n_estimators': Integer(100, 500),                        # Reduced range significantly\n",
        "    'num_leaves': Integer(31, 127),                           # Reduced upper bound\n",
        "    'max_depth': Integer(5, 15),                              # Narrower range\n",
        "    'min_child_samples': Integer(5, 20),                      # Smaller range\n",
        "    'subsample': Real(0.6, 0.9),                              # Narrower range\n",
        "    'colsample_bytree': Real(0.6, 0.9),                       # Narrower range\n",
        "    'reg_alpha': Real(0.01, 0.1, prior='log-uniform'),        # Smaller range\n",
        "    'reg_lambda': Real(0.01, 0.1, prior='log-uniform'),       # Smaller range\n",
        "}\n",
        "\n",
        "# Preprocessor setup with all engineered features (keep as is)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "# Process data for optimization\n",
        "X_processed = preprocessor.fit_transform(X_train)\n",
        "y_disease = y_train_encoded_df['Predicted_Disease']\n",
        "\n",
        "# Configure base LightGBM - switching to 'gbdt' for better speed\n",
        "disease_model = lgb.LGBMClassifier(\n",
        "    objective='multiclass',\n",
        "    boosting_type='gbdt',  # Changed from 'dart' to faster 'gbdt'\n",
        "    verbose=-1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Create early stopping callback for the optimization\n",
        "early_stopper = DeltaYStopper(delta=0.001, n_best=5)\n",
        "\n",
        "# Create a custom callback for the progress bar\n",
        "class ProgressBarCallback:\n",
        "    def __init__(self, total_iters=10):\n",
        "        self.pbar = tqdm(total=total_iters, desc=\"Bayesian Optimization Progress\")\n",
        "        self.iter_count = 0\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def __call__(self, res):\n",
        "        self.iter_count += 1\n",
        "        elapsed = time.time() - self.start_time\n",
        "        avg_time = elapsed / self.iter_count\n",
        "\n",
        "        # Update progress bar with metrics\n",
        "        if hasattr(res, 'func_vals') and len(res.func_vals) > 0:\n",
        "            best_score = -min(res.func_vals)  # Convert minimization to maximization\n",
        "            self.pbar.set_postfix({\n",
        "                'best_score': f'{best_score:.4f}',\n",
        "                'iter': self.iter_count,\n",
        "                'avg_time': f'{avg_time:.1f}s'\n",
        "            })\n",
        "\n",
        "        self.pbar.update(1)\n",
        "        return True\n",
        "\n",
        "# Number of optimization iterations\n",
        "n_iter = 10\n",
        "\n",
        "# Create Bayesian optimizer with fewer iterations\n",
        "optimizer = BayesSearchCV(\n",
        "    disease_model,\n",
        "    search_space,\n",
        "    n_iter=n_iter,     # Reduced from 25 to 10\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=0,  # Set to 0 to avoid cluttering the progress bar\n",
        "    scoring='accuracy',\n",
        "    random_state=42,\n",
        "    return_train_score=True  # Helpful for diagnostics\n",
        ")\n",
        "\n",
        "# Run optimization with early stopping and progress bar\n",
        "print(\"Starting Bayesian optimization with improved efficiency...\")\n",
        "progress_callback = ProgressBarCallback(total_iters=n_iter)\n",
        "optimizer.fit(X_processed, y_disease,\n",
        "              sample_weight=sample_weights,\n",
        "              callback=[early_stopper, progress_callback])\n",
        "\n",
        "# Get best model and parameters\n",
        "best_params = optimizer.best_params_\n",
        "best_score = optimizer.best_score_\n",
        "print(f\"Best CV accuracy: {best_score:.4f}\")\n",
        "print(f\"Best parameters: {best_params}\")\n",
        "\n",
        "# If you want the final model to still use 'dart' boosting, add it manually to best_params\n",
        "best_params['boosting_type'] = 'dart'  # Comment this out if you want to keep using 'gbdt'\n",
        "\n",
        "# Train final model with best parameters\n",
        "final_model = lgb.LGBMClassifier(\n",
        "    **best_params,\n",
        "    objective='multiclass',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Apply class weighting for problematic diseases\n",
        "final_model.fit(X_processed, y_disease, sample_weight=sample_weights)\n",
        "\n",
        "# Define valid target columns from the varied columns in training\n",
        "valid_target_cols = varied_cols_in_train  # Use the list created in Cell 5.5\n",
        "\n",
        "# Train remaining target models with standard parameters\n",
        "pipeline_models = {'Predicted_Disease': final_model}\n",
        "for col in valid_target_cols:\n",
        "    if col == 'Predicted_Disease':\n",
        "        continue\n",
        "    # Define standard parameters since lgb_params might not be defined\n",
        "    lgb_params = {\n",
        "        'objective': 'multiclass' if len(y_train_encoded_df[col].unique()) > 2 else 'binary',\n",
        "        'boosting_type': 'gbdt',  # Use faster algorithm for secondary targets\n",
        "        'learning_rate': 0.05,\n",
        "        'n_estimators': 200,\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1\n",
        "    }\n",
        "    # Use standard parameters for other targets\n",
        "    model = lgb.LGBMClassifier(**lgb_params)\n",
        "    model.fit(X_processed, y_train_encoded_df[col])\n",
        "    pipeline_models[col] = model\n",
        "\n",
        "# Create final pipeline\n",
        "pipeline = {\n",
        "    'preprocessor': preprocessor,\n",
        "    'models': pipeline_models,\n",
        "    'target_columns': valid_target_cols,\n",
        "    'predict': lambda X: np.column_stack([\n",
        "        pipeline['models'][col].predict(\n",
        "            pipeline['preprocessor'].transform(X)\n",
        "        ) for col in pipeline['target_columns']\n",
        "    ])\n",
        "}\n",
        "\n",
        "print(\"Optimized model training complete\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7.5: Feature Importance Analysis\n",
        "\n",
        "print(\"\\n--- Feature Importance Analysis ---\")\n",
        "disease_model = pipeline['models']['Predicted_Disease']\n",
        "\n",
        "# Get and plot feature importances\n",
        "feature_names = []\n",
        "if hasattr(preprocessor, 'get_feature_names_out'):\n",
        "    feature_names = preprocessor.get_feature_names_out()\n",
        "else:\n",
        "    # Fallback for older scikit-learn versions\n",
        "    feature_names = [\"feature_\" + str(i) for i in range(X_processed.shape[1])]\n",
        "\n",
        "# Get importances for the disease prediction model\n",
        "importances = disease_model.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Print top 20 most important features\n",
        "print(\"Top 20 most important features:\")\n",
        "for i in range(min(20, len(feature_names))):\n",
        "    print(f\"{i+1}. {feature_names[indices[i]]}: {importances[indices[i]]:.4f}\")\n",
        "\n",
        "# Analyze problematic classes\n",
        "problem_classes = ['GERD', 'Migraine', 'Osteoarthritis', 'Common Cold']\n",
        "problem_class_indices = [list(target_encoders['Predicted_Disease'].classes_).index(cls)\n",
        "                         for cls in problem_classes if cls in target_encoders['Predicted_Disease'].classes_]\n",
        "\n",
        "# For each problem class, show key predictive features\n",
        "print(\"\\nClass-specific important features:\")\n",
        "for cls, idx in zip(problem_classes, problem_class_indices):\n",
        "    print(f\"\\n{cls} predictive features:\")\n",
        "    # Get feature importance for this specific class\n",
        "    if hasattr(disease_model, 'feature_importances_'):\n",
        "        for i in range(5):  # Show top 5 features\n",
        "            print(f\"  - {feature_names[indices[i]]}\")"
      ],
      "metadata": {
        "id": "sAzj_iGXKdiw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "962322f3-f160-413b-cc42-e144726cd7ff"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Feature Importance Analysis ---\n",
            "Top 20 most important features:\n",
            "1. num__Vital_Interaction: 27570.0000\n",
            "2. num__WBC_Count: 25074.0000\n",
            "3. num__Glucose_Level: 24013.0000\n",
            "4. num__BP_HR_Ratio: 23549.0000\n",
            "5. num__Weight_kg: 21434.0000\n",
            "6. num__Temperature_C: 21167.0000\n",
            "7. num__Age: 19584.0000\n",
            "8. num__BP_Systolic: 16308.0000\n",
            "9. num__Heart_Rate: 15955.0000\n",
            "10. num__WBC_Squared: 15124.0000\n",
            "11. num__BMI: 12906.0000\n",
            "12. num__BP_Squared: 9968.0000\n",
            "13. num__HR_Squared: 8737.0000\n",
            "14. num__Symptom_Count: 7008.0000\n",
            "15. num__Temp_Squared: 6740.0000\n",
            "16. num__Glucose_Scaled: 6426.0000\n",
            "17. num__Fever_Severity: 5780.0000\n",
            "18. num__Has_Pain: 5508.0000\n",
            "19. num__Has_Cough: 5087.0000\n",
            "20. num__Has_Fever: 2943.0000\n",
            "\n",
            "Class-specific important features:\n",
            "\n",
            "GERD predictive features:\n",
            "  - num__Vital_Interaction\n",
            "  - num__WBC_Count\n",
            "  - num__Glucose_Level\n",
            "  - num__BP_HR_Ratio\n",
            "  - num__Weight_kg\n",
            "\n",
            "Migraine predictive features:\n",
            "  - num__Vital_Interaction\n",
            "  - num__WBC_Count\n",
            "  - num__Glucose_Level\n",
            "  - num__BP_HR_Ratio\n",
            "  - num__Weight_kg\n",
            "\n",
            "Osteoarthritis predictive features:\n",
            "  - num__Vital_Interaction\n",
            "  - num__WBC_Count\n",
            "  - num__Glucose_Level\n",
            "  - num__BP_HR_Ratio\n",
            "  - num__Weight_kg\n",
            "\n",
            "Common Cold predictive features:\n",
            "  - num__Vital_Interaction\n",
            "  - num__WBC_Count\n",
            "  - num__Glucose_Level\n",
            "  - num__BP_HR_Ratio\n",
            "  - num__Weight_kg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sMY03dEHZGp3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3815ecc6-4ea7-46e7-e4ef-c4b7fc98f762"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step: Prediction & Evaluation ---\n",
            "\n",
            "Making predictions on the test set...\n",
            "\n",
            "--- Predicted_Disease Evaluation ---\n",
            "Accuracy: 0.6847\n",
            "⚠️ Interpretation: Predicted_Disease accuracy (68.5%) is BELOW target. Check generation/model.\n",
            "\n",
            "Classification Report (Predicted_Disease - Decoded):\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "       Anxiety Disorder      0.667     0.700     0.683       240\n",
            "    Asthma Exacerbation      0.902     0.609     0.727       256\n",
            "    Bacterial Pneumonia      0.966     0.908     0.936       218\n",
            "            Common Cold      0.474     0.745     0.579       208\n",
            "        Diabetes Type 2      0.988     0.988     0.988       251\n",
            "                   GERD      0.408     0.474     0.439       211\n",
            "                Healthy      0.662     0.634     0.648       216\n",
            "           Hypertension      0.920     0.855     0.886       241\n",
            "         Hypothyroidism      0.692     0.635     0.662       230\n",
            "              Influenza      0.846     0.753     0.797       255\n",
            "               Migraine      0.383     0.361     0.372       227\n",
            "         Osteoarthritis      0.403     0.505     0.448       214\n",
            "Urinary Tract Infection      0.806     0.678     0.737       233\n",
            "\n",
            "               accuracy                          0.685      3000\n",
            "              macro avg      0.701     0.680     0.685      3000\n",
            "           weighted avg      0.712     0.685     0.692      3000\n",
            "\n",
            "\n",
            "--- Evaluation of Other ML Target Columns (Accuracy) ---\n",
            "Accuracy for 'Medicine_1': 0.7087\n",
            "Accuracy for 'Dosage_1': 0.7117\n",
            "Accuracy for 'Frequency_1': 0.7367\n",
            "Accuracy for 'Duration_1': 0.7693\n",
            "Accuracy for 'Medicine_2': 0.7293\n",
            "Accuracy for 'Dosage_2': 0.7293\n",
            "Accuracy for 'Frequency_2': 0.7307\n",
            "Accuracy for 'Duration_2': 0.8487\n",
            "Accuracy for 'Medicine_3': 0.9557\n",
            "Accuracy for 'Dosage_3': 0.9557\n",
            "Accuracy for 'Frequency_3': 0.9557\n",
            "Accuracy for 'Duration_3': 0.9923\n",
            "Accuracy for 'Polypharmacy_Risk': 0.8383\n",
            "\n",
            "Average Accuracy (Other ML Targets): 0.8202\n",
            "\n",
            "--- Overall Evaluation (Exact Match for ML Targets) ---\n",
            "Overall Accuracy (Exact Match Ratio - ML Targets): 0.5690\n"
          ]
        }
      ],
      "source": [
        "# Cell 8: Prediction & Evaluation\n",
        "\n",
        "print(\"\\n--- Step: Prediction & Evaluation ---\")\n",
        "\n",
        "if 'pipeline' not in locals() or not isinstance(pipeline, dict) or 'predict' not in pipeline:\n",
        "    print(\"⚠️ Error: Pipeline not properly initialized. Please run model training first.\")\n",
        "else:\n",
        "    try:\n",
        "        print(\"\\nMaking predictions on the test set...\")\n",
        "        y_pred_encoded = pipeline['predict'](X_test)\n",
        "\n",
        "        # Convert prediction numpy array to DataFrame with correct column names\n",
        "        y_pred_encoded_df = pd.DataFrame(y_pred_encoded, columns=pipeline['target_columns'])\n",
        "\n",
        "        # Convert float predictions to integers (fix for LabelEncoder)\n",
        "        for col in y_pred_encoded_df.columns:\n",
        "            y_pred_encoded_df[col] = y_pred_encoded_df[col].round().astype(int)\n",
        "\n",
        "        # --- Evaluate Predicted_Disease (Primary Target) ---\n",
        "        if 'Predicted_Disease' in y_pred_encoded_df.columns:\n",
        "            disease_true = y_test_encoded_df['Predicted_Disease']\n",
        "            disease_pred = y_pred_encoded_df['Predicted_Disease']\n",
        "            disease_accuracy = accuracy_score(disease_true, disease_pred)\n",
        "            print(f\"\\n--- Predicted_Disease Evaluation ---\")\n",
        "            print(f\"Accuracy: {disease_accuracy:.4f}\")\n",
        "\n",
        "            if disease_accuracy > 0.90:\n",
        "                print(f\"✅ Interpretation: Predicted_Disease accuracy target (>90%) MET! (Expected on this synthetic data)\")\n",
        "            elif disease_accuracy > 0.80:\n",
        "                print(f\"✓ Interpretation: Predicted_Disease accuracy ({disease_accuracy:.1%}) meets target of >80%.\")\n",
        "            else:\n",
        "                print(f\"⚠️ Interpretation: Predicted_Disease accuracy ({disease_accuracy:.1%}) is BELOW target. Check generation/model.\")\n",
        "\n",
        "            # Decode for classification report\n",
        "            disease_encoder = target_encoders['Predicted_Disease']\n",
        "\n",
        "            # Ensure values are within valid range for the encoder\n",
        "            valid_indices = list(range(len(disease_encoder.classes_)))\n",
        "            disease_pred_valid = np.clip(disease_pred, min(valid_indices), max(valid_indices))\n",
        "\n",
        "            disease_true_labels = disease_encoder.inverse_transform(disease_true)\n",
        "            disease_pred_labels = disease_encoder.inverse_transform(disease_pred_valid.astype(int))\n",
        "\n",
        "            print(f\"\\nClassification Report (Predicted_Disease - Decoded):\")\n",
        "            print(classification_report(disease_true_labels, disease_pred_labels,\n",
        "                                      target_names=disease_encoder.classes_, # Show class names\n",
        "                                      zero_division=0, digits=3))\n",
        "        else:\n",
        "            print(\"'Predicted_Disease' column not found in the predictions.\")\n",
        "\n",
        "        # --- Evaluate Other ML Targets ---\n",
        "        print(\"\\n--- Evaluation of Other ML Target Columns (Accuracy) ---\")\n",
        "        other_accuracies = {}\n",
        "        for col in pipeline['target_columns']:\n",
        "            if col == 'Predicted_Disease': continue # Skip primary target\n",
        "            if col in y_test_encoded_df.columns:\n",
        "                col_true = y_test_encoded_df[col]\n",
        "                col_pred = y_pred_encoded_df[col]\n",
        "                acc = accuracy_score(col_true, col_pred)\n",
        "                other_accuracies[col] = acc\n",
        "                print(f\"Accuracy for '{col}': {acc:.4f}\")\n",
        "\n",
        "        avg_other_accuracy = np.mean(list(other_accuracies.values())) if other_accuracies else 1.0\n",
        "        print(f\"\\nAverage Accuracy (Other ML Targets): {avg_other_accuracy:.4f}\")\n",
        "\n",
        "        # --- Overall Exact Match Ratio (Manual Calculation) ---\n",
        "        print(\"\\n--- Overall Evaluation (Exact Match for ML Targets) ---\")\n",
        "        try:\n",
        "            # Only compare columns present in both DataFrames\n",
        "            common_cols = [col for col in pipeline['target_columns'] if col in y_test_encoded_df.columns]\n",
        "            correct_elements = (y_test_encoded_df[common_cols].values == y_pred_encoded_df[common_cols].values)\n",
        "            correct_samples = np.all(correct_elements, axis=1)\n",
        "            exact_match_ratio = np.mean(correct_samples)\n",
        "            print(f\"Overall Accuracy (Exact Match Ratio - ML Targets): {exact_match_ratio:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Could not manually calculate Exact Match Ratio: {e}\")\n",
        "            exact_match_ratio = -1\n",
        "    except Exception as pred_error:\n",
        "        print(f\"Error during prediction/evaluation: {pred_error}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Saving Artifacts with Lambda Function Fix\n",
        "\n",
        "print(\"\\n--- Step: Saving Artifacts ---\")\n",
        "pipeline_file = 'synthetic_v2_pipeline.joblib'\n",
        "encoders_file = 'synthetic_v2_target_encoders.joblib'\n",
        "mappings_file = 'synthetic_v2_disease_mappings.joblib'\n",
        "\n",
        "try:\n",
        "    # Create a pickle-friendly version of the pipeline without lambda functions\n",
        "    pickle_friendly_pipeline = {\n",
        "        'preprocessor': pipeline['preprocessor'],\n",
        "        'models': pipeline['models'],\n",
        "        'target_columns': pipeline['target_columns']\n",
        "    }\n",
        "\n",
        "    # Define a placeholder function that will be replaced during loading\n",
        "    def predict_placeholder(X):\n",
        "        print(\"This is a placeholder. Pipeline needs to be reconstructed after loading.\")\n",
        "        return None\n",
        "\n",
        "    # Save prediction function code as a string for reference\n",
        "    predict_function_code = '''\n",
        "    def reconstruct_predict_function(pipeline):\n",
        "        def predict_function(X):\n",
        "            return np.column_stack([\n",
        "                pipeline['models'][col].predict(\n",
        "                    pipeline['preprocessor'].transform(X)\n",
        "                ) for col in pipeline['target_columns']\n",
        "            ])\n",
        "        return predict_function\n",
        "    '''\n",
        "\n",
        "    pickle_friendly_pipeline['predict_function_code'] = predict_function_code\n",
        "    pickle_friendly_pipeline['predict'] = predict_placeholder\n",
        "\n",
        "    # Save the pickle-friendly pipeline\n",
        "    joblib.dump(pickle_friendly_pipeline, pipeline_file)\n",
        "    print(f\"Pipeline saved to {pipeline_file}\")\n",
        "\n",
        "    # Save the target encoders\n",
        "    joblib.dump(target_encoders, encoders_file)\n",
        "    print(f\"Target encoders saved to {encoders_file}\")\n",
        "\n",
        "    # Save the disease-to-text mappings\n",
        "    joblib.dump(disease_to_text_mappings, mappings_file)\n",
        "    print(f\"Disease-to-text mappings saved to {mappings_file}\")\n",
        "\n",
        "    print(\"\\nArtifacts saved successfully.\")\n",
        "    print(\"You will need these files for deployment/prediction:\")\n",
        "    print(f\" - {pipeline_file}\")\n",
        "    print(f\" - {encoders_file}\")\n",
        "    print(f\" - {mappings_file}\")\n",
        "    print(\"\\nIMPORTANT: When loading the pipeline, you will need to reconstruct the predict function:\")\n",
        "    print(predict_function_code)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nError saving artifacts: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "id": "0iP0f8XSZIne",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3466833a-eb88-40cf-f5d6-713d12f075ed"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step: Saving Artifacts ---\n",
            "Pipeline saved to synthetic_v2_pipeline.joblib\n",
            "Target encoders saved to synthetic_v2_target_encoders.joblib\n",
            "Disease-to-text mappings saved to synthetic_v2_disease_mappings.joblib\n",
            "\n",
            "Artifacts saved successfully.\n",
            "You will need these files for deployment/prediction:\n",
            " - synthetic_v2_pipeline.joblib\n",
            " - synthetic_v2_target_encoders.joblib\n",
            " - synthetic_v2_disease_mappings.joblib\n",
            "\n",
            "IMPORTANT: When loading the pipeline, you will need to reconstruct the predict function:\n",
            "\n",
            "    def reconstruct_predict_function(pipeline):\n",
            "        def predict_function(X):\n",
            "            return np.column_stack([\n",
            "                pipeline['models'][col].predict(\n",
            "                    pipeline['preprocessor'].transform(X)\n",
            "                ) for col in pipeline['target_columns']\n",
            "            ])\n",
            "        return predict_function\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to load and reconstruct the pipeline\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Load the saved pipeline\n",
        "loaded_pipeline = joblib.load('synthetic_v2_pipeline.joblib')\n",
        "\n",
        "# Reconstruct the predict function\n",
        "def reconstruct_predict_function(pipeline):\n",
        "    def predict_function(X):\n",
        "        return np.column_stack([\n",
        "            pipeline['models'][col].predict(\n",
        "                pipeline['preprocessor'].transform(X)\n",
        "            ) for col in pipeline['target_columns']\n",
        "        ])\n",
        "    return predict_function\n",
        "\n",
        "# Add the reconstructed predict function to the pipeline\n",
        "loaded_pipeline['predict'] = reconstruct_predict_function(loaded_pipeline)"
      ],
      "metadata": {
        "id": "IZEv1oWkZktj"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "5LrFAQ_3ZKRn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce660438-dbde-4393-91ea-b131d57ccdd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step: Example Prediction Function ---\n",
            "Artifacts reloaded for prediction function.\n",
            "\n",
            "--- Example Prediction ---\n",
            "{\n",
            "  \"Predicted_Disease\": \"Influenza\",\n",
            "  \"Medicine_1\": \"Oseltamivir\",\n",
            "  \"Dosage_1\": \"75mg\",\n",
            "  \"Frequency_1\": \"Twice daily\",\n",
            "  \"Duration_1\": \"5 days\",\n",
            "  \"Medicine_2\": \"Acetaminophen\",\n",
            "  \"Dosage_2\": \"650mg\",\n",
            "  \"Frequency_2\": \"Every 6 hours\",\n",
            "  \"Duration_2\": \"As needed\",\n",
            "  \"Medicine_3\": \"Lisinopril\",\n",
            "  \"Dosage_3\": \"5mg\",\n",
            "  \"Frequency_3\": \"Once daily\",\n",
            "  \"Duration_3\": \"Ongoing\",\n",
            "  \"Polypharmacy_Risk\": \"Medium\",\n",
            "  \"Disease_Causes\": \"Influenza virus infection.\",\n",
            "  \"Instructions_1\": \"Start within 48h of symptoms.\",\n",
            "  \"Instructions_2\": \"For fever/pain relief.\",\n",
            "  \"Instructions_3\": \"For kidney protection/BP.\",\n",
            "  \"Personalized_Health_Tips\": \"Get annual flu shot, rest, fluids, avoid contact.\",\n",
            "  \"Polypharmacy_Recommendation\": \"Review potential interactions, especially Oseltamivir.\"\n",
            "}\n",
            "\n",
            "--- Example Prediction 2 ---\n",
            "{\n",
            "  \"Predicted_Disease\": \"Hypertension\",\n",
            "  \"Medicine_1\": \"Lisinopril\",\n",
            "  \"Dosage_1\": \"10mg\",\n",
            "  \"Frequency_1\": \"Once daily\",\n",
            "  \"Duration_1\": \"Ongoing\",\n",
            "  \"Medicine_2\": \"Hydrochlorothiazide\",\n",
            "  \"Dosage_2\": \"12.5mg\",\n",
            "  \"Frequency_2\": \"Once daily\",\n",
            "  \"Duration_2\": \"Ongoing\",\n",
            "  \"Medicine_3\": \"Lisinopril\",\n",
            "  \"Dosage_3\": \"5mg\",\n",
            "  \"Frequency_3\": \"Once daily\",\n",
            "  \"Duration_3\": \"Ongoing\",\n",
            "  \"Polypharmacy_Risk\": \"Medium\",\n",
            "  \"Disease_Causes\": \"Various factors including genetics, lifestyle, other conditions.\",\n",
            "  \"Instructions_1\": \"Monitor blood pressure.\",\n",
            "  \"Instructions_2\": \"Take in morning, monitor electrolytes.\",\n",
            "  \"Instructions_3\": \"For kidney protection/BP.\",\n",
            "  \"Personalized_Health_Tips\": \"Low sodium diet, exercise, weight management, limit alcohol.\",\n",
            "  \"Polypharmacy_Recommendation\": \"Regular BP checks, assess kidney function.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Cell 10: Updated Example Prediction Function with ALL Advanced Features\n",
        "\n",
        "print(\"\\n--- Step: Example Prediction Function ---\")\n",
        "\n",
        "# Define input_features before using them in the prediction function\n",
        "input_features = [\n",
        "    'Patient_ID', 'Age', 'Gender', 'Blood_Group', 'Weight_kg',\n",
        "    'Has_Fever', 'Has_Cough', 'Has_Fatigue', 'Has_Pain',\n",
        "    'Has_Hypertension', 'Has_Diabetes', 'Temperature_C',\n",
        "    'Heart_Rate', 'BP_Systolic', 'WBC_Count', 'Glucose_Level'\n",
        "    # Note: All engineered features will be created within the function\n",
        "]\n",
        "\n",
        "# Load artifacts (demonstration)\n",
        "try:\n",
        "    loaded_pipeline = joblib.load(pipeline_file)\n",
        "    loaded_encoders = joblib.load(encoders_file)\n",
        "    loaded_mappings = joblib.load(mappings_file)\n",
        "    print(\"Artifacts reloaded for prediction function.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error reloading artifacts: {e}. Prediction function cannot be tested.\")\n",
        "    # Define a dummy function or exit if artifacts are needed\n",
        "    def predict_synthetic_patient_outcomes(*args, **kwargs): return {\"Error\": \"Artifacts not loaded\"}\n",
        "\n",
        "if 'loaded_pipeline' in locals(): # Proceed only if artifacts loaded\n",
        "    def predict_synthetic_patient_outcomes(patient_features):\n",
        "        \"\"\"\n",
        "        Predicts outcomes for a single patient using the loaded pipeline, encoders, and mappings.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Add missing fields and required engineered features\n",
        "            enriched_features = patient_features.copy()\n",
        "            age = patient_features.get('Age', 45)\n",
        "\n",
        "            # ====== BASIC FEATURES ======\n",
        "            # Create interaction features between binary symptoms\n",
        "            enriched_features['fever_cough'] = patient_features.get('Has_Fever', 0) * patient_features.get('Has_Cough', 0)\n",
        "            enriched_features['fever_fatigue'] = patient_features.get('Has_Fever', 0) * patient_features.get('Has_Fatigue', 0)\n",
        "            enriched_features['pain_fatigue'] = patient_features.get('Has_Pain', 0) * patient_features.get('Has_Fatigue', 0)\n",
        "            enriched_features['hypertension_diabetes'] = patient_features.get('Has_Hypertension', 0) * patient_features.get('Has_Diabetes', 0)\n",
        "\n",
        "            # Create age groups\n",
        "            if age <= 18:\n",
        "                enriched_features['Age_Group'] = 'Child'\n",
        "            elif age <= 35:\n",
        "                enriched_features['Age_Group'] = 'Young_Adult'\n",
        "            elif age <= 50:\n",
        "                enriched_features['Age_Group'] = 'Adult'\n",
        "            elif age <= 65:\n",
        "                enriched_features['Age_Group'] = 'Senior'\n",
        "            else:\n",
        "                enriched_features['Age_Group'] = 'Elderly'\n",
        "\n",
        "            # Create BMI (approximation)\n",
        "            enriched_features['BMI'] = patient_features.get('Weight_kg', 70) / ((patient_features.get('Weight_kg', 70) / 30) ** 2)\n",
        "\n",
        "            # Vital sign combinations\n",
        "            enriched_features['BP_HR_Ratio'] = patient_features.get('BP_Systolic', 120) / max(patient_features.get('Heart_Rate', 80), 1)\n",
        "            enriched_features['Fever_Severity'] = patient_features.get('Temperature_C', 37.0) - 37.0\n",
        "\n",
        "            # Basic disease patterns\n",
        "            enriched_features['GERD_Pattern'] = 1 if (age > 40 and patient_features.get('Has_Pain', 0) == 1\n",
        "                                                   and patient_features.get('Has_Cough', 0) == 0) else 0\n",
        "            enriched_features['Migraine_Pattern'] = 1 if (age < 50 and patient_features.get('Has_Pain', 0) == 1\n",
        "                                                       and patient_features.get('Has_Fever', 0) == 0) else 0\n",
        "            enriched_features['Osteo_Pattern'] = 1 if (age > 55 and patient_features.get('Has_Pain', 0) == 1\n",
        "                                                    and patient_features.get('Weight_kg', 70) > 75) else 0\n",
        "            enriched_features['Cold_Pattern'] = 1 if (patient_features.get('Has_Fever', 0) == 1\n",
        "                                                   and patient_features.get('Has_Cough', 0) == 1\n",
        "                                                   and patient_features.get('Temperature_C', 37.0) < 38.5) else 0\n",
        "\n",
        "            # ====== ADVANCED DISEASE-SPECIFIC PATTERNS ======\n",
        "            enriched_features['GERD_Advanced'] = 1 if (age > 40 and patient_features.get('Has_Pain', 0) == 1\n",
        "                                               and patient_features.get('Has_Cough', 0) == 0\n",
        "                                               and patient_features.get('BP_Systolic', 120) < 130\n",
        "                                               and patient_features.get('Heart_Rate', 80) < 80\n",
        "                                               and patient_features.get('Has_Fatigue', 0) == 0) else 0\n",
        "\n",
        "            enriched_features['Migraine_Advanced'] = 1 if (age < 50 and patient_features.get('Has_Pain', 0) == 1\n",
        "                                                  and patient_features.get('Has_Fever', 0) == 0\n",
        "                                                  and patient_features.get('Heart_Rate', 80) > 70\n",
        "                                                  and patient_features.get('Has_Fatigue', 1) == 1\n",
        "                                                  and patient_features.get('Temperature_C', 37.0) < 37.2) else 0\n",
        "\n",
        "            enriched_features['Osteo_Advanced'] = 1 if (age > 55 and patient_features.get('Has_Pain', 0) == 1\n",
        "                                               and patient_features.get('Weight_kg', 70) > 75\n",
        "                                               and patient_features.get('Has_Hypertension', 0) == 0\n",
        "                                               and patient_features.get('Has_Fever', 0) == 0\n",
        "                                               and patient_features.get('BP_Systolic', 120) > 110) else 0\n",
        "\n",
        "            enriched_features['Cold_Advanced'] = 1 if (patient_features.get('Has_Fever', 0) == 1\n",
        "                                              and patient_features.get('Has_Cough', 0) == 1\n",
        "                                              and patient_features.get('Temperature_C', 37.0) < 38.5\n",
        "                                              and patient_features.get('Temperature_C', 37.0) > 37.0\n",
        "                                              and patient_features.get('WBC_Count', 7.0) < 10\n",
        "                                              and patient_features.get('Has_Fatigue', 0) == 1) else 0\n",
        "\n",
        "            # ====== EXTREMELY SPECIFIC PATTERNS ======\n",
        "            enriched_features['GERD_Specific'] = 1 if (age > 40 and patient_features.get('Has_Pain', 0) == 1\n",
        "                                               and patient_features.get('Has_Cough', 0) == 0\n",
        "                                               and patient_features.get('BP_Systolic', 120) < 130\n",
        "                                               and patient_features.get('Temperature_C', 37.0) < 37.0\n",
        "                                               and patient_features.get('WBC_Count', 7.0) < 8.0\n",
        "                                               and patient_features.get('Has_Hypertension', 0) == 0\n",
        "                                               and patient_features.get('Has_Diabetes', 0) == 0) else 0\n",
        "\n",
        "            enriched_features['Migraine_Specific'] = 1 if (age < 50 and patient_features.get('Has_Pain', 0) == 1\n",
        "                                                 and patient_features.get('Has_Fever', 0) == 0\n",
        "                                                 and patient_features.get('Heart_Rate', 80) > 70\n",
        "                                                 and patient_features.get('Heart_Rate', 80) < 100\n",
        "                                                 and patient_features.get('Has_Fatigue', 0) == 1\n",
        "                                                 and patient_features.get('BP_Systolic', 120) < 130\n",
        "                                                 and patient_features.get('Has_Hypertension', 0) == 0) else 0\n",
        "\n",
        "            enriched_features['Osteo_Specific'] = 1 if (age > 55 and patient_features.get('Has_Pain', 0) == 1\n",
        "                                                and patient_features.get('Weight_kg', 70) > 75\n",
        "                                                and patient_features.get('Has_Fever', 0) == 0\n",
        "                                                and patient_features.get('Has_Cough', 0) == 0\n",
        "                                                and patient_features.get('Has_Fatigue', 0) == 0\n",
        "                                                and patient_features.get('WBC_Count', 7.0) < 9.0\n",
        "                                                and patient_features.get('BP_Systolic', 120) > 120) else 0\n",
        "\n",
        "            enriched_features['Cold_Specific'] = 1 if (patient_features.get('Has_Fever', 0) == 1\n",
        "                                              and patient_features.get('Has_Cough', 0) == 1\n",
        "                                              and patient_features.get('Temperature_C', 37.0) < 38.0\n",
        "                                              and patient_features.get('Temperature_C', 37.0) > 37.2\n",
        "                                              and patient_features.get('WBC_Count', 7.0) < 9.0\n",
        "                                              and patient_features.get('WBC_Count', 7.0) > 5.0\n",
        "                                              and patient_features.get('Has_Fatigue', 0) == 1\n",
        "                                              and patient_features.get('Has_Pain', 0) == 0) else 0\n",
        "\n",
        "            # ====== TRIPLE COMBINATIONS ======\n",
        "            enriched_features['Fever_Cough_Fatigue'] = (patient_features.get('Has_Fever', 0) *\n",
        "                                                      patient_features.get('Has_Cough', 0) *\n",
        "                                                      patient_features.get('Has_Fatigue', 0))\n",
        "\n",
        "            enriched_features['Pain_Fever_Fatigue'] = (patient_features.get('Has_Pain', 0) *\n",
        "                                                     patient_features.get('Has_Fever', 0) *\n",
        "                                                     patient_features.get('Has_Fatigue', 0))\n",
        "\n",
        "            enriched_features['Pain_Cough_Fatigue'] = (patient_features.get('Has_Pain', 0) *\n",
        "                                                     patient_features.get('Has_Cough', 0) *\n",
        "                                                     patient_features.get('Has_Fatigue', 0))\n",
        "\n",
        "            enriched_features['Vital_Interaction'] = (patient_features.get('Temperature_C', 37.0) *\n",
        "                                                    patient_features.get('Heart_Rate', 80) *\n",
        "                                                    patient_features.get('BP_Systolic', 120)) / 1000\n",
        "\n",
        "            # ====== MATHEMATICAL TRANSFORMATIONS ======\n",
        "            enriched_features['Temp_Squared'] = (patient_features.get('Temperature_C', 37.0) - 37.0) ** 2\n",
        "            enriched_features['BP_Squared'] = ((patient_features.get('BP_Systolic', 120) - 120) / 10) ** 2\n",
        "            enriched_features['HR_Squared'] = ((patient_features.get('Heart_Rate', 80) - 75) / 10) ** 2\n",
        "            enriched_features['WBC_Squared'] = ((patient_features.get('WBC_Count', 7.5) - 7.5) / 2) ** 2\n",
        "            enriched_features['Glucose_Scaled'] = (patient_features.get('Glucose_Level', 100) - 100) / 10\n",
        "\n",
        "            # ====== AGE-SYMPTOM COMBINATIONS ======\n",
        "            enriched_features['Young_With_Fever'] = 1 if (age < 35 and patient_features.get('Has_Fever', 0) == 1) else 0\n",
        "            enriched_features['Senior_With_Pain'] = 1 if (age > 65 and patient_features.get('Has_Pain', 0) == 1) else 0\n",
        "            enriched_features['Middle_With_Fatigue'] = 1 if (age > 35 and age < 65 and\n",
        "                                                         patient_features.get('Has_Fatigue', 0) == 1) else 0\n",
        "\n",
        "            # ====== BLOOD COUNT INDICATORS ======\n",
        "            enriched_features['High_WBC'] = 1 if patient_features.get('WBC_Count', 7.0) > 10.0 else 0\n",
        "            enriched_features['Low_WBC'] = 1 if patient_features.get('WBC_Count', 7.0) < 5.0 else 0\n",
        "            enriched_features['Normal_WBC'] = 1 if (patient_features.get('WBC_Count', 7.0) >= 5.0 and\n",
        "                                                  patient_features.get('WBC_Count', 7.0) <= 10.0) else 0\n",
        "\n",
        "            # ====== CONDITIONAL FEATURES ======\n",
        "            enriched_features['Likely_Infection'] = 1 if (patient_features.get('Has_Fever', 0) == 1 and\n",
        "                                                        patient_features.get('WBC_Count', 7.0) > 9.0 and\n",
        "                                                        patient_features.get('Temperature_C', 37.0) > 37.5) else 0\n",
        "\n",
        "            enriched_features['Likely_Chronic'] = 1 if (patient_features.get('Has_Fever', 0) == 0 and\n",
        "                                                      patient_features.get('Has_Fatigue', 0) == 1 and\n",
        "                                                      patient_features.get('WBC_Count', 7.0) < 9.0) else 0\n",
        "\n",
        "            enriched_features['Likely_Acute'] = 1 if ((patient_features.get('Has_Fever', 0) == 1 or\n",
        "                                                    patient_features.get('Has_Pain', 0) == 1) and\n",
        "                                                    patient_features.get('Has_Fatigue', 0) == 0) else 0\n",
        "\n",
        "            # ====== SYMPTOM COUNT ======\n",
        "            enriched_features['Symptom_Count'] = (patient_features.get('Has_Fever', 0) +\n",
        "                                                patient_features.get('Has_Cough', 0) +\n",
        "                                                patient_features.get('Has_Fatigue', 0) +\n",
        "                                                patient_features.get('Has_Pain', 0) +\n",
        "                                                patient_features.get('Has_Hypertension', 0) +\n",
        "                                                patient_features.get('Has_Diabetes', 0))\n",
        "\n",
        "            # Add Patient_ID if missing (required by some models)\n",
        "            if 'Patient_ID' not in enriched_features:\n",
        "                enriched_features['Patient_ID'] = 0  # Placeholder value\n",
        "\n",
        "            # 1. Create DataFrame from enriched features\n",
        "            input_df = pd.DataFrame([enriched_features])\n",
        "\n",
        "            # 2. Predict using the loaded pipeline components\n",
        "            X_processed = loaded_pipeline['preprocessor'].transform(input_df)\n",
        "\n",
        "            # Run prediction for each model\n",
        "            predictions = []\n",
        "            for col in loaded_pipeline['target_columns']:\n",
        "                model = loaded_pipeline['models'][col]\n",
        "                pred = model.predict(X_processed)[0]  # Get single prediction value\n",
        "                predictions.append(pred)\n",
        "\n",
        "            # Convert to DataFrame with column names\n",
        "            pred_encoded_df = pd.DataFrame([predictions], columns=loaded_pipeline['target_columns'])\n",
        "\n",
        "            # 3. Decode ML Predictions\n",
        "            predictions_decoded = {}\n",
        "            predicted_disease_label = \"Error: Disease Not Predicted\"\n",
        "\n",
        "            for col in pred_encoded_df.columns:\n",
        "                encoder = loaded_encoders.get(col)\n",
        "                if encoder:\n",
        "                    encoded_value = int(pred_encoded_df[col].iloc[0])  # Ensure integer\n",
        "                    decoded_value = encoder.inverse_transform([encoded_value])[0]\n",
        "                    predictions_decoded[col] = decoded_value\n",
        "                    # Store the predicted disease label for mapping lookup\n",
        "                    if col == 'Predicted_Disease':\n",
        "                        predicted_disease_label = decoded_value\n",
        "                else:\n",
        "                    predictions_decoded[col] = f\"Error: No encoder found for {col}\"\n",
        "\n",
        "            # 4. Lookup Mapped Textual Outputs\n",
        "            mapped_outputs = loaded_mappings.get(predicted_disease_label, {})\n",
        "            if not mapped_outputs:\n",
        "                print(f\"Warning: No mapping found for predicted disease '{predicted_disease_label}'. Returning defaults.\")\n",
        "                # Provide default values\n",
        "                for map_col in mapping_target_cols:\n",
        "                    predictions_decoded[map_col] = \"Mapping Unavailable\"\n",
        "            else:\n",
        "                for map_col in mapping_target_cols:\n",
        "                    predictions_decoded[map_col] = mapped_outputs.get(map_col, f\"Info unavailable for {map_col}\")\n",
        "\n",
        "            # 5. Combine all results\n",
        "            final_results = {}\n",
        "            all_output_cols = list(pred_encoded_df.columns) + mapping_target_cols\n",
        "            for col in all_output_cols:\n",
        "                if col in predictions_decoded:\n",
        "                    final_results[col] = predictions_decoded[col]\n",
        "\n",
        "            return final_results\n",
        "\n",
        "        except Exception as e:\n",
        "            import traceback\n",
        "            traceback_str = traceback.format_exc()\n",
        "            return {\"Error\": f\"Prediction failed: {str(e)}\", \"Traceback\": traceback_str}\n",
        "\n",
        "\n",
        "    # --- Example Usage ---\n",
        "    print(\"\\n--- Example Prediction ---\")\n",
        "    # Create sample input matching one of the disease profiles (e.g., Influenza-like)\n",
        "    sample_input = {\n",
        "        'Age': 45, 'Gender': 'Male', 'Blood_Group': 'O+', 'Weight_kg': 80.5,\n",
        "        'Has_Fever': 1, 'Has_Cough': 1, 'Has_Fatigue': 1, 'Has_Pain': 1, # Simulating Influenza\n",
        "        'Has_Hypertension': 0, 'Has_Diabetes': 0,\n",
        "        'Temperature_C': 38.6, 'Heart_Rate': 88, 'BP_Systolic': 121,\n",
        "        'WBC_Count': 9.5, 'Glucose_Level': 102\n",
        "    }\n",
        "\n",
        "    prediction = predict_synthetic_patient_outcomes(sample_input)\n",
        "    print(json.dumps(prediction, indent=2))\n",
        "\n",
        "    # Example 2 (Simulating Hypertension-like)\n",
        "    print(\"\\n--- Example Prediction 2 ---\")\n",
        "    sample_input_2 = {\n",
        "        'Age': 65, 'Gender': 'Female', 'Blood_Group': 'A-', 'Weight_kg': 95.0,\n",
        "        'Has_Fever': 0, 'Has_Cough': 0, 'Has_Fatigue': 0, 'Has_Pain': 0, # Often asymptomatic\n",
        "        'Has_Hypertension': 1, 'Has_Diabetes': 0, # Known HTN\n",
        "        'Temperature_C': 36.7, 'Heart_Rate': 71, 'BP_Systolic': 148, # High BP\n",
        "        'WBC_Count': 6.8, 'Glucose_Level': 94\n",
        "    }\n",
        "    prediction_2 = predict_synthetic_patient_outcomes(sample_input_2)\n",
        "    print(json.dumps(prediction_2, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "YgjPQ5YpZN3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a4221ac-953d-49e2-88ce-fd6d1ac39e91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Final Notes ---\n",
            "Model training and evaluation complete using '/content/Synthetic_Medical_Dataset_v2.csv'.\n",
            "High accuracy achieved is expected due to the SYNTHETIC nature of the data.\n",
            "The model learned the patterns deliberately embedded during generation.\n",
            "REMINDER: This model and dataset are for development/pipeline testing ONLY, NOT for real medical use.\n",
            "Saved artifacts (synthetic_v2_pipeline.joblib, synthetic_v2_target_encoders.joblib, synthetic_v2_disease_mappings.joblib) are ready for use in deployment.\n"
          ]
        }
      ],
      "source": [
        "# Cell 11: Final Notes\n",
        "print(\"\\n--- Final Notes ---\")\n",
        "print(f\"Model training and evaluation complete using '{file_path}'.\")\n",
        "print(\"High accuracy achieved is expected due to the SYNTHETIC nature of the data.\")\n",
        "print(\"The model learned the patterns deliberately embedded during generation.\")\n",
        "print(\"REMINDER: This model and dataset are for development/pipeline testing ONLY, NOT for real medical use.\")\n",
        "print(f\"Saved artifacts ({pipeline_file}, {encoders_file}, {mappings_file}) are ready for use in deployment.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11.5: Specialist Models for Problem Classes\n",
        "\n",
        "print(\"\\n--- Training Specialist Models for Problem Classes ---\")\n",
        "\n",
        "# Identify problem classes\n",
        "problem_classes = ['GERD', 'Migraine', 'Osteoarthritis', 'Common Cold']\n",
        "problem_target = 'Predicted_Disease'\n",
        "\n",
        "# Create binary target for each problem class\n",
        "problem_targets = {}\n",
        "for problem_class in problem_classes:\n",
        "    # Get class index\n",
        "    class_idx = list(target_encoders[problem_target].classes_).index(problem_class)\n",
        "    # Create binary target (1 for this class, 0 for others)\n",
        "    problem_targets[problem_class] = (y_train_encoded_df[problem_target] == class_idx).astype(int)\n",
        "    print(f\"Created binary target for {problem_class} with {problem_targets[problem_class].sum()} positive examples\")\n",
        "\n",
        "# For each problem class, train a specialized binary classifier\n",
        "specialist_models = {}\n",
        "for problem_class in problem_classes:\n",
        "    print(f\"\\nTraining specialist model for {problem_class}...\")\n",
        "\n",
        "    # Create massive weight for the positive class (1:100 ratio)\n",
        "    class_weight = {0: 1, 1: 100}\n",
        "\n",
        "    # Train a specialized binary classifier\n",
        "    model = lgb.LGBMClassifier(\n",
        "        n_estimators=2000,\n",
        "        learning_rate=0.01,\n",
        "        max_depth=15,\n",
        "        num_leaves=127,\n",
        "        class_weight=class_weight,\n",
        "        boosting_type='dart',\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        reg_alpha=0.1,\n",
        "        reg_lambda=0.1,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_processed, problem_targets[problem_class])\n",
        "\n",
        "    # Store the model\n",
        "    specialist_models[problem_class] = model\n",
        "\n",
        "    # Check training accuracy\n",
        "    train_preds = model.predict(X_processed)\n",
        "    train_acc = accuracy_score(problem_targets[problem_class], train_preds)\n",
        "    print(f\"Training accuracy for {problem_class}: {train_acc:.4f}\")\n",
        "\n",
        "# Add these models to our pipeline for potential ensemble use during prediction\n",
        "pipeline['specialist_models'] = specialist_models\n",
        "\n",
        "# Modify prediction function to use specialized models when appropriate\n",
        "original_predict = pipeline['predict']\n",
        "\n",
        "def ensemble_predict(X):\n",
        "    # Get base predictions\n",
        "    base_preds = original_predict(X)\n",
        "\n",
        "    # Process X\n",
        "    X_processed = pipeline['preprocessor'].transform(X)\n",
        "\n",
        "    # For each instance, check if any specialist model gives high confidence\n",
        "    for i in range(len(X)):\n",
        "        for problem_class in problem_classes:\n",
        "            # Get class index\n",
        "            class_idx = list(target_encoders[problem_target].classes_).index(problem_class)\n",
        "\n",
        "            # Get specialist model prediction probability\n",
        "            specialist_prob = specialist_models[problem_class].predict_proba(X_processed[i:i+1])[0][1]\n",
        "\n",
        "            # If specialist is very confident (>0.85), override the prediction\n",
        "            if specialist_prob > 0.85:\n",
        "                base_preds[i, target_columns.index(problem_target)] = class_idx\n",
        "\n",
        "    return base_preds\n",
        "\n",
        "# Update pipeline with ensemble prediction\n",
        "pipeline['predict'] = ensemble_predict\n",
        "print(\"Specialist models integrated into prediction pipeline\")"
      ],
      "metadata": {
        "id": "1nvJfdhOKqlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bca56b39-0f7a-4fa7-9e1e-4d4fe3a6d3d8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training Specialist Models for Problem Classes ---\n",
            "Created binary target for GERD with 963 positive examples\n",
            "Created binary target for Migraine with 865 positive examples\n",
            "Created binary target for Osteoarthritis with 918 positive examples\n",
            "Created binary target for Common Cold with 913 positive examples\n",
            "\n",
            "Training specialist model for GERD...\n",
            "Training accuracy for GERD: 0.9217\n",
            "\n",
            "Training specialist model for Migraine...\n",
            "Training accuracy for Migraine: 0.9307\n",
            "\n",
            "Training specialist model for Osteoarthritis...\n",
            "Training accuracy for Osteoarthritis: 0.9338\n",
            "\n",
            "Training specialist model for Common Cold...\n",
            "Training accuracy for Common Cold: 0.9680\n",
            "Specialist models integrated into prediction pipeline\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a2bdbdc732f641d8bd6f74744d361677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4640d3fc651341b29d983932c86e93d2",
              "IPY_MODEL_2aaf03156f0c4771896ab9b63028cdb4",
              "IPY_MODEL_643ca826110d41c6b28dcfed9615c747"
            ],
            "layout": "IPY_MODEL_6be9bab4174b4d639cc13b6c524a5eb6"
          }
        },
        "4640d3fc651341b29d983932c86e93d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a027fe9693664a06bf9422600cb907fa",
            "placeholder": "​",
            "style": "IPY_MODEL_66d1692af5fc414cb90e4a1237d9da94",
            "value": "Bayesian Optimization Progress:  10%"
          }
        },
        "2aaf03156f0c4771896ab9b63028cdb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac47d83fa3c44ee5bee777fd97e403e0",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_711adb47a45b4dc496f99b106d348e6d",
            "value": 1
          }
        },
        "643ca826110d41c6b28dcfed9615c747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc2f286d425543ad8167bd01e13e5f70",
            "placeholder": "​",
            "style": "IPY_MODEL_d41be1433a7a405ab05a51aabe89b575",
            "value": " 1/10 [02:01&lt;18:09, 121.03s/it, best_score=0.6857, iter=1, avg_time=121.0s]"
          }
        },
        "6be9bab4174b4d639cc13b6c524a5eb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a027fe9693664a06bf9422600cb907fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66d1692af5fc414cb90e4a1237d9da94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac47d83fa3c44ee5bee777fd97e403e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "711adb47a45b4dc496f99b106d348e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc2f286d425543ad8167bd01e13e5f70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d41be1433a7a405ab05a51aabe89b575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}